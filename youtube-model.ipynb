{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing ELECTRA, ALBERT, DistilBERT, and TinyBERT for YouTube Comment Sentiment Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 1. DistilBERT: Distillation-Based Compression\n",
    "\n",
    "**How:**  \n",
    "DistilBERT uses *knowledge distillation* — training a smaller student model to mimic a larger BERT teacher.\n",
    "\n",
    "**Why Interesting:**  \n",
    "- Achieves about 40% fewer parameters and 60% faster inference while retaining around 97% of BERT’s performance.  \n",
    "- Illustrates simple but effective model compression via distillation.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ALBERT: Parameter Sharing & Factorization\n",
    "\n",
    "**How:**  \n",
    "ALBERT reduces model size by *sharing parameters across layers* and *factorizing embeddings*.\n",
    "\n",
    "**Why Interesting:**  \n",
    "- Dramatically reduces the number of parameters without heavily impacting capacity.  \n",
    "- Introduces *sentence-order prediction* to improve pretraining efficiency.  \n",
    "- Shows that *architectural changes* (not just distillation) can yield compact, fast, yet strong models.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ELECTRA: Efficient Pretraining via Discriminators\n",
    "\n",
    "**How:**  \n",
    "ELECTRA replaces masked token prediction with a *replaced token detection* task, where a generator replaces some tokens and a discriminator predicts which tokens were replaced.\n",
    "\n",
    "**Why Interesting:**  \n",
    "- Makes pretraining more sample-efficient and faster to converge.  \n",
    "- Smaller ELECTRA models often outperform comparable-sized BERTs despite using fewer compute resources during training.  \n",
    "- Highlights innovation in *pretraining objectives* rather than model size or architecture alone.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. TinyBERT: Distillation with Layer-Wise Compression\n",
    "\n",
    "**How:**  \n",
    "TinyBERT applies *knowledge distillation* focusing on both *transformer layer compression* and *embedding compression*, using a two-stage distillation from both the encoder and prediction layers.\n",
    "\n",
    "**Why Interesting:**  \n",
    "- Produces a very compact model with fewer layers (typically 4 or 6), substantially reducing size and latency.  \n",
    "- Maintains strong performance close to larger BERT models on various NLP tasks including sentiment analysis.  \n",
    "- Designed specifically for deployment on resource-constrained devices, balancing speed and accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Compare These?\n",
    "\n",
    "- They represent **complementary approaches** to making transformers faster and lighter:  \n",
    "  - Distillation (DistilBERT, TinyBERT)  \n",
    "  - Parameter efficiency (ALBERT)  \n",
    "  - Pretraining objective redesign (ELECTRA)  \n",
    "- Comparing accuracy, speed, size, and resource consumption on the same tasks reveals trade-offs important for real applications — especially on resource-restricted devices.  \n",
    "- Helps practitioners **choose the best fit** for their particular constraints (e.g., mobile deployment vs. cloud inference).  \n",
    "- Informs **future model design** by highlighting which efficiency techniques work best in which contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:17.638165Z",
     "iopub.status.busy": "2025-05-07T01:29:17.637902Z",
     "iopub.status.idle": "2025-05-07T01:29:45.195872Z",
     "shell.execute_reply": "2025-05-07T01:29:45.195309Z",
     "shell.execute_reply.started": "2025-05-07T01:29:17.638119Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification as SeqModClf\n",
    "import torch\n",
    "import numpy \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.197444Z",
     "iopub.status.busy": "2025-05-07T01:29:45.196913Z",
     "iopub.status.idle": "2025-05-07T01:29:45.201233Z",
     "shell.execute_reply": "2025-05-07T01:29:45.200528Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.197425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.202020Z",
     "iopub.status.busy": "2025-05-07T01:29:45.201802Z",
     "iopub.status.idle": "2025-05-07T01:29:45.339219Z",
     "shell.execute_reply": "2025-05-07T01:29:45.338575Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.201996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...   neutral\n",
       "1  here in nz 50 of retailers don’t even have con...  negative\n",
       "2  i will forever acknowledge this channel with t...  positive\n",
       "3  whenever i go to a place that doesn’t take app...  negative\n",
       "4  apple pay is so convenient secure and easy to ...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"YoutubeCommentsDataSet.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.341230Z",
     "iopub.status.busy": "2025-05-07T01:29:45.340647Z",
     "iopub.status.idle": "2025-05-07T01:29:45.362026Z",
     "shell.execute_reply": "2025-05-07T01:29:45.361367Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.341210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18408 entries, 0 to 18407\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Comment    18364 non-null  object\n",
      " 1   Sentiment  18408 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 287.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 18,408 rows and 2 columns: \"Comment\" (with 18,364 non-null text entries) and \"Sentiment\" (fully populated with sentiment labels). Both columns contain text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.362895Z",
     "iopub.status.busy": "2025-05-07T01:29:45.362710Z",
     "iopub.status.idle": "2025-05-07T01:29:45.375316Z",
     "shell.execute_reply": "2025-05-07T01:29:45.374654Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.362880Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment      44\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.376345Z",
     "iopub.status.busy": "2025-05-07T01:29:45.376071Z",
     "iopub.status.idle": "2025-05-07T01:29:45.394199Z",
     "shell.execute_reply": "2025-05-07T01:29:45.393596Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.376324Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18403</th>\n",
       "      <td>i really like the point about engineering tool...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18404</th>\n",
       "      <td>i’ve just started exploring this field and thi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18405</th>\n",
       "      <td>excelente video con una pregunta filosófica pr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406</th>\n",
       "      <td>hey daniel just discovered your channel a coup...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18407</th>\n",
       "      <td>this is great focus is key a playful approach ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment Sentiment\n",
       "0      lets not forget that apple pay in 2014 require...   neutral\n",
       "1      here in nz 50 of retailers don’t even have con...  negative\n",
       "2      i will forever acknowledge this channel with t...  positive\n",
       "3      whenever i go to a place that doesn’t take app...  negative\n",
       "4      apple pay is so convenient secure and easy to ...  positive\n",
       "...                                                  ...       ...\n",
       "18403  i really like the point about engineering tool...  positive\n",
       "18404  i’ve just started exploring this field and thi...  positive\n",
       "18405  excelente video con una pregunta filosófica pr...   neutral\n",
       "18406  hey daniel just discovered your channel a coup...  positive\n",
       "18407  this is great focus is key a playful approach ...  positive\n",
       "\n",
       "[18364 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only the comments in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(str(text)) == \"en\"\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "dataset['is_english'] = dataset['Comment'].apply(is_english)\n",
    "dataset = dataset[dataset['is_english']]\n",
    "dataset = dataset[['Comment', 'Sentiment']]\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale the positive value and upscale the negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    10642\n",
       "neutral      3319\n",
       "negative     2296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "neutral     3319\n",
      "positive    3319\n",
      "negative    3319\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_positive = dataset[dataset['Sentiment'] == 'positive']\n",
    "df_neutral = dataset[dataset['Sentiment'] == 'neutral']\n",
    "df_negative = dataset[dataset['Sentiment'] == 'negative']\n",
    "\n",
    "\n",
    "df_positive_downsampled = resample(df_positive,\n",
    "                                   replace=False,\n",
    "                                   n_samples=3319,\n",
    "                                   random_state=42)\n",
    "\n",
    "df_negative_upsampled = resample(df_negative,\n",
    "                                 replace=True,     \n",
    "                                 n_samples=3319,\n",
    "                                 random_state=42)\n",
    "\n",
    "dataset = pd.concat([df_positive_downsampled, df_neutral, df_negative_upsampled])\n",
    "dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(dataset['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "Negative = 0\n",
    "Neutral = 1 \n",
    "Positive = 2\n",
    "\n",
    "To ensure consistent and clear mapping of sentiment categories to numbers across all models, which helps fairly compare their performance since they all work with the same standardized numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.395007Z",
     "iopub.status.busy": "2025-05-07T01:29:45.394778Z",
     "iopub.status.idle": "2025-05-07T01:29:45.414440Z",
     "shell.execute_reply": "2025-05-07T01:29:45.413875Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.394987Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imanu\\AppData\\Local\\Temp\\ipykernel_15608\\3674117635.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset['Sentiment'] = dataset['Sentiment'].replace({'negative':0,'neutral':1,'positive':2})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seriously</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when some random people are able to teach this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841 diagram venn 1508 ds pathway 1940 role of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we want the blood in the streets this is actua...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wish ethan would meet andrew tate in real li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Sentiment\n",
       "0                                          seriously          1\n",
       "1  when some random people are able to teach this...          1\n",
       "2  841 diagram venn 1508 ds pathway 1940 role of ...          1\n",
       "3  we want the blood in the streets this is actua...          2\n",
       "4  i wish ethan would meet andrew tate in real li...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode train & test\n",
    "def encode_labels(dataset):\n",
    "     dataset['Sentiment'] = dataset['Sentiment'].replace({'negative':0,'neutral':1,'positive':2})\n",
    "     return dataset\n",
    "\n",
    "encoded_dataset = encode_labels(dataset)\n",
    "\n",
    "encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.415227Z",
     "iopub.status.busy": "2025-05-07T01:29:45.415014Z",
     "iopub.status.idle": "2025-05-07T01:29:45.419395Z",
     "shell.execute_reply": "2025-05-07T01:29:45.418629Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.415211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.rename(columns={'Comment': 'text', 'Sentiment': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.420278Z",
     "iopub.status.busy": "2025-05-07T01:29:45.420036Z",
     "iopub.status.idle": "2025-05-07T01:29:45.433861Z",
     "shell.execute_reply": "2025-05-07T01:29:45.433183Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.420258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seriously</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when some random people are able to teach this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841 diagram venn 1508 ds pathway 1940 role of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we want the blood in the streets this is actua...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wish ethan would meet andrew tate in real li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                          seriously      1\n",
       "1  when some random people are able to teach this...      1\n",
       "2  841 diagram venn 1508 ds pathway 1940 role of ...      1\n",
       "3  we want the blood in the streets this is actua...      2\n",
       "4  i wish ethan would meet andrew tate in real li...      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "Allocate 30% of  data for testing and 70% for training, which provides a balanced split that allows enough data for the model to learn while reserving a sizable portion to reliably evaluate its performance on unseen examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.436412Z",
     "iopub.status.busy": "2025-05-07T01:29:45.436221Z",
     "iopub.status.idle": "2025-05-07T01:29:45.567180Z",
     "shell.execute_reply": "2025-05-07T01:29:45.566656Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.436398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(encoded_dataset, test_size = 0.3, \n",
    "                               random_state = 42, \n",
    "                               stratify = encoded_dataset['label'])\n",
    "\n",
    "train.to_csv(\"train.csv\", index=True)\n",
    "test.to_csv(\"test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T00:45:07.943337Z",
     "iopub.status.busy": "2025-05-07T00:45:07.943033Z",
     "iopub.status.idle": "2025-05-07T00:45:07.947336Z",
     "shell.execute_reply": "2025-05-07T00:45:07.946383Z",
     "shell.execute_reply.started": "2025-05-07T00:45:07.943318Z"
    }
   },
   "source": [
    "## Conver pandas dataset to HuggingFace dataset\n",
    "Hugging Face offers specialized, integrated support for transformer models, including standardized evaluation metrics, easy access to pretrained models, and streamlined training/evaluation pipelines—making model comparison more efficient, consistent, and tailored for NLP tasks than general-purpose pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.567975Z",
     "iopub.status.busy": "2025-05-07T01:29:45.567807Z",
     "iopub.status.idle": "2025-05-07T01:29:45.616261Z",
     "shell.execute_reply": "2025-05-07T01:29:45.615556Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.567961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_hf = Dataset.from_pandas(train.reset_index(drop= True))\n",
    "test_hf = Dataset.from_pandas(test.reset_index(drop= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.617542Z",
     "iopub.status.busy": "2025-05-07T01:29:45.617310Z",
     "iopub.status.idle": "2025-05-07T01:29:45.625412Z",
     "shell.execute_reply": "2025-05-07T01:29:45.624700Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.617519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['anna karenina and the death of ivan ilyich are among the best books ive ever read if you do read tolstoy make sure to go with the pevear and volokhonsky translations they allow you to get the most from his works'], 'label': [2]}\n"
     ]
    }
   ],
   "source": [
    "print(train_hf[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.626372Z",
     "iopub.status.busy": "2025-05-07T01:29:45.626182Z",
     "iopub.status.idle": "2025-05-07T01:29:45.633410Z",
     "shell.execute_reply": "2025-05-07T01:29:45.632669Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.626358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['im gonna add myself to the many thank yous im one hour in and i already understood more than i did in a two days course i got from work you singlehandedly gave me the trust that even i can learn python and programming this video is worth gold to me right now thank you mosh'], 'label': [2]}\n"
     ]
    }
   ],
   "source": [
    "print(test_hf[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:45.634534Z",
     "iopub.status.busy": "2025-05-07T01:29:45.634186Z",
     "iopub.status.idle": "2025-05-07T01:29:45.645350Z",
     "shell.execute_reply": "2025-05-07T01:29:45.644594Z",
     "shell.execute_reply.started": "2025-05-07T01:29:45.634513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets = DatasetDict({ 'train': train_hf, 'test' : test_hf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T03:13:41.422212Z",
     "iopub.status.busy": "2025-05-07T03:13:41.421842Z",
     "iopub.status.idle": "2025-05-07T03:13:50.325626Z",
     "shell.execute_reply": "2025-05-07T03:13:50.324660Z",
     "shell.execute_reply.started": "2025-05-07T03:13:41.422161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model moved to cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer_distilbert = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "model = SeqModClf.from_pretrained('distilbert-base-uncased', num_labels = 3)\n",
    "\n",
    "device  =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f'model moved to {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6969/6969 [00:01<00:00, 5208.43 examples/s]\n",
      "Map: 100%|██████████| 2988/2988 [00:00<00:00, 5345.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'anna karenina and the death of ivan ilyich are among the best books ive ever read if you do read tolstoy make sure to go with the pevear and volokhonsky translations they allow you to get the most from his works', 'label': 2, 'input_ids': [101, 4698, 8129, 3981, 1998, 1996, 2331, 1997, 7332, 6335, 10139, 2818, 2024, 2426, 1996, 2190, 2808, 4921, 2063, 2412, 3191, 2065, 2017, 2079, 3191, 2000, 4877, 29578, 2191, 2469, 2000, 2175, 2007, 1996, 21877, 3726, 2906, 1998, 5285, 6559, 8747, 5874, 11913, 2027, 3499, 2017, 2000, 2131, 1996, 2087, 2013, 2010, 2573, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenizer_function(dataset):\n",
    "    comments = [str(comment) for comment in dataset['text']]\n",
    "    return tokenizer(comments, padding = 'max_length',truncation = True)\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenizer_function, batched= True)\n",
    "\n",
    "print(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:29:53.044840Z",
     "iopub.status.busy": "2025-05-07T01:29:53.044450Z",
     "iopub.status.idle": "2025-05-07T01:49:51.750000Z",
     "shell.execute_reply": "2025-05-07T01:49:51.749387Z",
     "shell.execute_reply.started": "2025-05-07T01:29:53.044813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imanu\\AppData\\Local\\Temp\\ipykernel_15608\\1102259049.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_distilbert = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2616' max='2616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2616/2616 09:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.761400</td>\n",
       "      <td>0.535244</td>\n",
       "      <td>0.797523</td>\n",
       "      <td>0.795542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>0.492904</td>\n",
       "      <td>0.846720</td>\n",
       "      <td>0.845967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.661840</td>\n",
       "      <td>0.850736</td>\n",
       "      <td>0.851354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2616, training_loss=0.3810840115999228, metrics={'train_runtime': 544.2904, 'train_samples_per_second': 38.411, 'train_steps_per_second': 4.806, 'total_flos': 2769545293728768.0, 'train_loss': 0.3810840115999228, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './distilbert',\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    warmup_steps = 500,\n",
    "    weight_decay = 0.01,\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'eval_f1_score',\n",
    "    greater_is_better = True,\n",
    "    report_to = 'none',\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = numpy.argmax(logits, axis = -1)\n",
    "    Accuracy_score = accuracy_score(labels,predictions)\n",
    "    F1_score = f1_score(labels, predictions, average = 'weighted')\n",
    "    return {'accuracy_score':Accuracy_score,'f1_score':F1_score}\n",
    "\n",
    "trainer_distilbert = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['test'],\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer_distilbert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELECTRA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:49:51.750918Z",
     "iopub.status.busy": "2025-05-07T01:49:51.750673Z",
     "iopub.status.idle": "2025-05-07T01:49:54.564159Z",
     "shell.execute_reply": "2025-05-07T01:49:54.563547Z",
     "shell.execute_reply.started": "2025-05-07T01:49:51.750898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "tokenizer_electra = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "\n",
    "model_electra = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_electra.to(device)\n",
    "print(f'Model moved to {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6969/6969 [00:05<00:00, 1341.48 examples/s]\n",
      "Map: 100%|██████████| 2988/2988 [00:02<00:00, 1298.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': tensor(2), 'input_ids': tensor([  101,  4698,  8129,  3981,  1998,  1996,  2331,  1997,  7332,  6335,\n",
      "        10139,  2818,  2024,  2426,  1996,  2190,  2808,  4921,  2063,  2412,\n",
      "         3191,  2065,  2017,  2079,  3191,  2000,  4877, 29578,  2191,  2469,\n",
      "         2000,  2175,  2007,  1996, 21877,  3726,  2906,  1998,  5285,  6559,\n",
      "         8747,  5874, 11913,  2027,  3499,  2017,  2000,  2131,  1996,  2087,\n",
      "         2013,  2010,  2573,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def electra_tokenizer_function(dataset):\n",
    "    comments = [str(comment) for comment in dataset['text']]\n",
    "    return tokenizer_electra(comments, padding='max_length', truncation=True)\n",
    "\n",
    "# Tokenize raw datasets for ELECTRA\n",
    "tokenized_datasets_electra = datasets.map(electra_tokenizer_function, batched=True)\n",
    "\n",
    "# Remove the original 'text' column\n",
    "tokenized_datasets_electra = tokenized_datasets_electra.remove_columns(['text'])\n",
    "\n",
    "# Set the format to PyTorch tensors\n",
    "tokenized_datasets_electra.set_format('torch')\n",
    "\n",
    "# Check the first tokenized example in the train split\n",
    "print(tokenized_datasets_electra['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:49:54.565164Z",
     "iopub.status.busy": "2025-05-07T01:49:54.564898Z",
     "iopub.status.idle": "2025-05-07T01:49:54.780666Z",
     "shell.execute_reply": "2025-05-07T01:49:54.779637Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.565125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imanu\\AppData\\Local\\Temp\\ipykernel_15608\\2713297849.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_electra = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2616' max='2616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2616/2616 18:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.517625</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.792671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>0.457086</td>\n",
       "      <td>0.860776</td>\n",
       "      <td>0.859351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.532247</td>\n",
       "      <td>0.880187</td>\n",
       "      <td>0.880611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2616, training_loss=0.4010152138701273, metrics={'train_runtime': 1106.378, 'train_samples_per_second': 18.897, 'train_steps_per_second': 2.364, 'total_flos': 5500912224439296.0, 'train_loss': 0.4010152138701273, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./electra',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1_score',\n",
    "    greater_is_better=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = numpy.argmax(logits, axis=-1)\n",
    "    Accuracy_score = accuracy_score(labels, predictions)\n",
    "    F1_score = f1_score(labels, predictions, average='weighted')\n",
    "    return {'accuracy_score': Accuracy_score, 'f1_score': F1_score}\n",
    "\n",
    "trainer_electra = Trainer(\n",
    "    model=model_electra,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets_electra['train'],\n",
    "    eval_dataset=tokenized_datasets_electra['test'],\n",
    "    tokenizer=tokenizer_electra,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_electra.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALBERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.781075Z",
     "iopub.status.idle": "2025-05-07T01:49:54.781318Z",
     "shell.execute_reply": "2025-05-07T01:49:54.781220Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.781210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "\n",
    "tokenizer_albert = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "model_albert = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_albert.to(device)\n",
    "print(f'Model moved to {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6969/6969 [00:02<00:00, 3064.64 examples/s]\n",
      "Map: 100%|██████████| 2988/2988 [00:00<00:00, 3083.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': tensor(2), 'input_ids': tensor([    2,  2823,  7512,  1673,    17,    14,   372,    16,  5489,    31,\n",
      "          102,  3870,    50,   497,    14,   246,   964,  5568,   462,  1302,\n",
      "          100,    42,   107,  1302,    20, 24239,  7452,   233,   562,    20,\n",
      "          162,    29,    14,  3560,   195,   512,    17,  2250,   111, 23925,\n",
      "         2397, 13610,    59,  1655,    42,    20,   164,    14,   127,    37,\n",
      "           33,   693,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load ALBERT tokenizer\n",
    "tokenizer_albert = AutoTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "def albert_tokenizer_function(dataset):\n",
    "    comments = [str(comment) for comment in dataset['text']]\n",
    "    return tokenizer_albert(comments, padding='max_length', truncation=True)\n",
    "\n",
    "# Tokenize raw datasets for ALBERT\n",
    "tokenized_datasets_albert = datasets.map(albert_tokenizer_function, batched=True)\n",
    "\n",
    "# Remove the original 'text' column\n",
    "tokenized_datasets_albert = tokenized_datasets_albert.remove_columns(['text'])\n",
    "\n",
    "# Set the format to PyTorch tensors\n",
    "tokenized_datasets_albert.set_format('torch')\n",
    "\n",
    "# Check the first tokenized example in the train split\n",
    "print(tokenized_datasets_albert['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.782291Z",
     "iopub.status.idle": "2025-05-07T01:49:54.782605Z",
     "shell.execute_reply": "2025-05-07T01:49:54.782456Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.782443Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imanu\\AppData\\Local\\Temp\\ipykernel_15608\\4073434684.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_albert = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2616' max='2616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2616/2616 18:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.805458</td>\n",
       "      <td>0.652945</td>\n",
       "      <td>0.626613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.690717</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.719341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>0.603099</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.776898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2616, training_loss=0.6909599537514036, metrics={'train_runtime': 1129.3365, 'train_samples_per_second': 18.513, 'train_steps_per_second': 2.316, 'total_flos': 499687003524096.0, 'train_loss': 0.6909599537514036, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./albert',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1_score',\n",
    "    greater_is_better=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = numpy.argmax(logits, axis=-1)\n",
    "    Accuracy_score = accuracy_score(labels, predictions)\n",
    "    F1_score = f1_score(labels, predictions, average='weighted')\n",
    "    return {'accuracy_score': Accuracy_score, 'f1_score': F1_score}\n",
    "\n",
    "trainer_albert = Trainer(\n",
    "    model=model_albert,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets_albert['train'],\n",
    "    eval_dataset=tokenized_datasets_albert['test'],\n",
    "    tokenizer=tokenizer_albert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_albert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyBERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "okenizer_tinybert = AutoTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "\n",
    "model_tinybert = AutoModelForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_tinybert.to(device)\n",
    "print(f'Model moved to {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6969/6969 [00:02<00:00, 3389.64 examples/s]\n",
      "Map: 100%|██████████| 2988/2988 [00:00<00:00, 3506.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': tensor(2), 'input_ids': tensor([  101,  4698,  8129,  3981,  1998,  1996,  2331,  1997,  7332,  6335,\n",
      "        10139,  2818,  2024,  2426,  1996,  2190,  2808,  4921,  2063,  2412,\n",
      "         3191,  2065,  2017,  2079,  3191,  2000,  4877, 29578,  2191,  2469,\n",
      "         2000,  2175,  2007,  1996, 21877,  3726,  2906,  1998,  5285,  6559,\n",
      "         8747,  5874, 11913,  2027,  3499,  2017,  2000,  2131,  1996,  2087,\n",
      "         2013,  2010,  2573,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load TinyBERT tokenizer - use the appropriate TinyBERT checkpoint\n",
    "tokenizer_tinybert = AutoTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "\n",
    "def tinybert_tokenizer_function(dataset):\n",
    "    comments = [str(comment) for comment in dataset['text']]\n",
    "    return tokenizer_tinybert(comments, padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Tokenize raw datasets for TinyBERT\n",
    "tokenized_datasets_tinybert = datasets.map(tinybert_tokenizer_function, batched=True)\n",
    "\n",
    "# Remove the original 'text' column\n",
    "tokenized_datasets_tinybert = tokenized_datasets_tinybert.remove_columns(['text'])\n",
    "\n",
    "# Set the format to PyTorch tensors\n",
    "tokenized_datasets_tinybert.set_format('torch')\n",
    "\n",
    "# Check the first tokenized example in the train split\n",
    "print(tokenized_datasets_tinybert['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imanu\\AppData\\Local\\Temp\\ipykernel_15608\\885667533.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_tinybert = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2616' max='2616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2616/2616 03:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.581269</td>\n",
       "      <td>0.765395</td>\n",
       "      <td>0.761287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500400</td>\n",
       "      <td>0.588607</td>\n",
       "      <td>0.794511</td>\n",
       "      <td>0.788036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.601350</td>\n",
       "      <td>0.814926</td>\n",
       "      <td>0.813804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2616, training_loss=0.5290130839799887, metrics={'train_runtime': 198.668, 'train_samples_per_second': 105.236, 'train_steps_per_second': 13.168, 'total_flos': 299805496888320.0, 'train_loss': 0.5290130839799887, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training arguments (adjust output_dir as needed)\n",
    "training_args_tinybert = TrainingArguments(\n",
    "    output_dir='./tinybert',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1_score',\n",
    "    greater_is_better=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "# Metrics function (same as ALBERT)\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = numpy.argmax(logits, axis=-1)\n",
    "    Accuracy_score = accuracy_score(labels, predictions)\n",
    "    F1_score = f1_score(labels, predictions, average='weighted')\n",
    "    return {'accuracy_score': Accuracy_score, 'f1_score': F1_score}\n",
    "\n",
    "# Assuming you have TinyBERT-tokenized datasets\n",
    "trainer_tinybert = Trainer(\n",
    "    model=model_tinybert,\n",
    "    args=training_args_tinybert,\n",
    "    train_dataset=tokenized_datasets_tinybert['train'],\n",
    "    eval_dataset=tokenized_datasets_tinybert['test'],\n",
    "    tokenizer=tokenizer_tinybert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_tinybert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.783484Z",
     "iopub.status.idle": "2025-05-07T01:49:54.783753Z",
     "shell.execute_reply": "2025-05-07T01:49:54.783638Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.783622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT eval metrics: {'eval_loss': 0.6618396043777466, 'eval_accuracy_score': 0.8507362784471219, 'eval_f1_score': 0.8513544995260339, 'eval_runtime': 20.851, 'eval_samples_per_second': 143.302, 'eval_steps_per_second': 8.968, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELECTRA eval metrics: {'eval_loss': 0.5322473049163818, 'eval_accuracy_score': 0.8801874163319946, 'eval_f1_score': 0.8806113089944043, 'eval_runtime': 43.931, 'eval_samples_per_second': 68.016, 'eval_steps_per_second': 4.257, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALBERT eval metrics: {'eval_loss': 0.6030990481376648, 'eval_accuracy_score': 0.7777777777777778, 'eval_f1_score': 0.7768983419917441, 'eval_runtime': 47.193, 'eval_samples_per_second': 63.314, 'eval_steps_per_second': 3.962, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='187' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/187 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyBERT eval metrics: {'eval_loss': 0.6013495326042175, 'eval_accuracy_score': 0.8149263721552878, 'eval_f1_score': 0.8138042383855054, 'eval_runtime': 8.471, 'eval_samples_per_second': 352.733, 'eval_steps_per_second': 22.075, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "distilbert_metrics = trainer_distilbert.evaluate()\n",
    "print(\"DistilBERT eval metrics:\", distilbert_metrics)\n",
    "electra_metrics = trainer_electra.evaluate()\n",
    "print(\"ELECTRA eval metrics:\", electra_metrics)\n",
    "albert_metrics = trainer_albert.evaluate()\n",
    "print(\"ALBERT eval metrics:\", albert_metrics)\n",
    "tinybert_metrics = trainer_tinybert.evaluate()\n",
    "print(\"TinyBERT eval metrics:\", tinybert_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.784595Z",
     "iopub.status.idle": "2025-05-07T01:49:54.784897Z",
     "shell.execute_reply": "2025-05-07T01:49:54.784732Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.784717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model  Accuracy  F1 Score\n",
      "0  DistilBERT  0.850736  0.851354\n",
      "1     ELECTRA  0.880187  0.880611\n",
      "2      ALBERT  0.777778  0.776898\n",
      "3    TinyBERT  0.814926  0.813804\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Model\": [\"DistilBERT\", \"ELECTRA\", \"ALBERT\", \"TinyBERT\"],\n",
    "    \"Accuracy\": [\n",
    "        distilbert_metrics.get(\"eval_accuracy_score\"),\n",
    "        electra_metrics.get(\"eval_accuracy_score\"),\n",
    "        albert_metrics.get(\"eval_accuracy_score\"),\n",
    "        tinybert_metrics.get(\"eval_accuracy_score\"),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        distilbert_metrics.get(\"eval_f1_score\"),\n",
    "        electra_metrics.get(\"eval_f1_score\"),\n",
    "        albert_metrics.get(\"eval_f1_score\"),\n",
    "        tinybert_metrics.get(\"eval_f1_score\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(data)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.785498Z",
     "iopub.status.idle": "2025-05-07T01:49:54.785694Z",
     "shell.execute_reply": "2025-05-07T01:49:54.785609Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.785600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Added one more color for TinyBERT\n",
    "colors = [\"skyblue\", \"orange\", \"green\", \"purple\"]  # customize as you like\n",
    "\n",
    "axes[0].bar(df_metrics[\"Model\"], df_metrics[\"Accuracy\"], color=colors)\n",
    "axes[0].set_title(\"Model Accuracy\")\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "axes[1].bar(df_metrics[\"Model\"], df_metrics[\"F1 Score\"], color=colors)\n",
    "axes[1].set_title(\"Model F1 Score (Weighted)\")\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].set_ylabel(\"F1 Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model based on F1-score\n",
    "Comparing models based on F1-score is ideal because it balances precision and recall, providing a more comprehensive measure of performance—especially for imbalanced datasets—than accuracy alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.786673Z",
     "iopub.status.idle": "2025-05-07T01:49:54.786971Z",
     "shell.execute_reply": "2025-05-07T01:49:54.786833Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.786818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusion: The best model is **ELECTRA** with an F1 Score of 0.8806 and an Accuracy of 0.8802.\n",
      "Saved the best model (ELECTRA) to variable 'model'.\n"
     ]
    }
   ],
   "source": [
    "# Find the best model name based on F1 Score\n",
    "best_model_name = df_metrics.loc[df_metrics['F1 Score'].idxmax(), 'Model']\n",
    "\n",
    "# Map model name to your actual model object\n",
    "model_map = {\n",
    "    'DistilBERT': trainer_distilbert.model,\n",
    "    'ELECTRA': trainer_electra.model,\n",
    "    'ALBERT': trainer_albert.model,\n",
    "    'TinyBERT': trainer_tinybert.model  \n",
    "}\n",
    "\n",
    "# Save the best model to variable 'model'\n",
    "model = model_map[best_model_name]\n",
    "\n",
    "# Get row with best model metrics\n",
    "best_metrics = df_metrics[df_metrics['Model'] == best_model_name].iloc[0]\n",
    "\n",
    "print(f\"Conclusion: The best model is **{best_model_name}** \"\n",
    "      f\"with an F1 Score of {best_metrics['F1 Score']:.4f} \"\n",
    "      f\"and an Accuracy of {best_metrics['Accuracy']:.4f}.\")\n",
    "\n",
    "print(f\"Saved the best model ({best_model_name}) to variable 'model'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.788124Z",
     "iopub.status.idle": "2025-05-07T01:49:54.788443Z",
     "shell.execute_reply": "2025-05-07T01:49:54.788301Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.788287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bestModel/youtube-sentiment-model\\\\tokenizer_config.json',\n",
       " './bestModel/youtube-sentiment-model\\\\special_tokens_map.json',\n",
       " './bestModel/youtube-sentiment-model\\\\vocab.txt',\n",
       " './bestModel/youtube-sentiment-model\\\\added_tokens.json',\n",
       " './bestModel/youtube-sentiment-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./bestModel/youtube-sentiment-model')\n",
    "tokenizer.save_pretrained('./bestModel/youtube-sentiment-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.788977Z",
     "iopub.status.idle": "2025-05-07T01:49:54.789306Z",
     "shell.execute_reply": "2025-05-07T01:49:54.789164Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.789150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/working/youtube-sentiment-model'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/working/youtube-sentiment-model'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sentiment_classifier = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/kaggle/working/youtube-sentiment-model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/kaggle/working/youtube-sentiment-model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:812\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m    808\u001b[39m     pretrained_model_name_or_path = model\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig) \u001b[38;5;129;01mand\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    811\u001b[39m     \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcache_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m     hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    209\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    210\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    211\u001b[39m     **kwargs,\n\u001b[32m    212\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\transformers\\utils\\hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    464\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m resolved_files = \u001b[43m[\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfull_filenames\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\transformers\\utils\\hub.py:471\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    464\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m    470\u001b[39m resolved_files = [\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    472\u001b[39m ]\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\transformers\\utils\\hub.py:134\u001b[39m, in \u001b[36m_get_cache_file_to_return\u001b[39m\u001b[34m(path_or_repo_id, full_filename, cache_dir, revision)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cache_file_to_return\u001b[39m(\n\u001b[32m    131\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m, full_filename: \u001b[38;5;28mstr\u001b[39m, cache_dir: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m ):\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     resolved_file = \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file != _CACHED_NO_EXIST:\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mzip\u001b[39m(signature.parameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[32m    103\u001b[39m     kwargs.items(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[32m    104\u001b[39m ):\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    109\u001b[39m         has_token = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\College\\Semester 4\\Natural Language Processing\\Assignment\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRepo id must be a string, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(repo_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must use alphanumeric chars or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m--\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m\u001b[33m are\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m forbidden, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m cannot start or end the name, max length is 96:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/working/youtube-sentiment-model'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_classifier = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='./bestModel/youtube-sentiment-model',\n",
    "    tokenizer='./bestModel/youtube-sentiment-model',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T01:49:54.790082Z",
     "iopub.status.idle": "2025-05-07T01:49:54.790368Z",
     "shell.execute_reply": "2025-05-07T01:49:54.790269Z",
     "shell.execute_reply.started": "2025-05-07T01:49:54.790256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_comments = [\n",
    "    \"This tutorial is fantastic and extremely helpful!\",\n",
    "    \"I'm a bit confused by some parts of this explanation.\",\n",
    "    \"The content is decent, not particularly good or bad.\"\n",
    "]\n",
    "\n",
    "predictions = sentiment_classifier(new_comments)\n",
    "\n",
    "for comment, prediction in zip(new_comments, predictions):\n",
    "    print(f\"Comment: \\\"{comment}\\\"\")\n",
    "    predicted_label_str = prediction['label']  # e.g. 'LABEL_0'\n",
    "    predicted_label_int = int(predicted_label_str.split('_')[-1])\n",
    "    confidence = prediction['score']\n",
    "    print(f\"Predicted Sentiment Label: {predicted_label_int} (Confidence: {confidence:.4f})\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6560918,
     "sourceId": 10599713,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
